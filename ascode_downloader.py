import os
import time
import requests
from bs4 import BeautifulSoup

# === 1. ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ IDì™€ ë¹„ë°€ë²ˆí˜¸ ì„¤ì • ===
username = input("â–¶ ì‚¬ìš©ì IDë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 20243100): ").strip()
password = input("â–¶ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()

# === 2. ê¸°ë³¸ ì„¤ì • ===
save_root = "./ascode_solutions"
base_url = "http://ascode.org"
status_url = f"{base_url}/status.php"

# === 3. ë¡œê·¸ì¸ í•¨ìˆ˜ ì¶”ê°€ ===
def login(username, password):
    login_url = f"{base_url}/login.php"
    session = requests.Session()
    
    # ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ í¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    login_page_url = f"{base_url}/loginpage.php"
    resp = session.get(login_page_url)
    
    # ë¡œê·¸ì¸ ìš”ì²­
    login_data = {
        "user_id": username,
        "password": password
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36',
        'Referer': login_page_url,
        'Accept': '*/*',
        'Accept-Encoding': 'gzip, deflate',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
    }
    
    resp = session.post(login_url, data=login_data, headers=headers, allow_redirects=True)
    
    # ë¡œê·¸ì¸ ì„±ê³µ ì—¬ë¶€ í™•ì¸
    if check_login_status(session):
        print(f"âœ… {username}ë‹˜ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œê·¸ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return session
    else:
        print("âŒ ë¡œê·¸ì¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ì IDì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None

# === 4. ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ í•¨ìˆ˜ ìˆ˜ì • ===
def check_login_status(session):
    try:
        check_url = f"{base_url}/template/ascode/profile.php?138760013"
        resp = session.get(check_url)
        soup = BeautifulSoup(resp.text, 'html.parser')
        logout_link = soup.find('a', string='Logout')
        return logout_link is not None
    except Exception as e:
        print("ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜:", e)
        return False

# === 5. ì œì¶œ ê¸°ë¡ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ===
def fetch_user_submissions(session, user_id, top=None, prevtop=None, result="4"):
    url = f"{status_url}?user_id={user_id}&jresult={result}"
    if top:
        url += f"&top={top}"
    if prevtop:
        url += f"&prevtop={prevtop}"
    try:
        resp = session.get(url)
        resp.raise_for_status()
        return resp.text
    except requests.RequestException as e:
        print(f"ì œì¶œ ê¸°ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None

# === 6. ì œì¶œ ì½”ë“œ ì €ì¥ í•¨ìˆ˜ ìˆ˜ì • ===
def save_code_from_page(session, user_id, top=None, prevtop=None):
    page_html = fetch_user_submissions(session, user_id, top, prevtop, result="4")
    if not page_html:
        return False

    soup = BeautifulSoup(page_html, 'html.parser')
    table = soup.find('table')
    if not table:
        print("ì œì¶œ ê¸°ë¡ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    headers = [th.get_text(strip=True).lower() for th in table.find('tr').find_all('th')]
    try:
        runid_idx = headers.index('runid')
        problem_idx = headers.index('problem')
        lang_idx = headers.index('language')
    except ValueError as e:
        print(f"í•„ìš”í•œ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print(f"ë°œê²¬ëœ í—¤ë”: {headers}")
        return False

    submissions = []
    for row in table.find_all('tr')[1:]:
        cols = row.find_all('td')
        if len(cols) <= max(runid_idx, problem_idx, lang_idx):
            continue
        runid = cols[runid_idx].get_text(strip=True)
        problem_id = cols[problem_idx].get_text(strip=True)
        language_cell = cols[lang_idx]
        language_text = language_cell.get_text(strip=True)

        edit_link = None
        for a_tag in language_cell.find_all('a'):
            if 'edit' in a_tag.get_text().lower():
                edit_link = a_tag.get('href')
                break
        if not edit_link:
            edit_link = f"showsource.php?id={runid}"
        if edit_link.startswith('/'):
            edit_link = f"{base_url}{edit_link}"
        elif not edit_link.startswith('http'):
            edit_link = f"{base_url}/{edit_link}"

        if '/' in language_text:
            language = language_text.split('/')[0]
        else:
            language = language_text.replace('Edit', '').strip()

        submissions.append((runid, problem_id, language, edit_link))

    for idx, (runid, problem_id, language, source_link) in enumerate(submissions):
        print(f"[{idx+1}/{len(submissions)}] RunID {runid}, ë¬¸ì œ {problem_id}, ì–¸ì–´ {language} ì²˜ë¦¬ ì¤‘...")
        try:
            resp = session.get(source_link)
            resp.raise_for_status()
        except requests.RequestException as e:
            print(f"[{problem_id}] ì½”ë“œ ìš”ì²­ ì‹¤íŒ¨: {e}")
            continue

        soup = BeautifulSoup(resp.text, 'html.parser')
        code_element = soup.find('pre') or soup.find('textarea')
        if code_element:
            code_text = code_element.get_text()
            extension = get_file_extension(language)
            problem_folder = os.path.join(save_root, problem_id)
            os.makedirs(problem_folder, exist_ok=True)
            file_path = os.path.join(problem_folder, f"solution_{runid}{extension}")
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(code_text)
            print(f"[{problem_id}] ì½”ë“œ(RunID: {runid}) ì €ì¥ ì™„ë£Œ: {file_path}")
        else:
            print(f"[{problem_id}] ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        time.sleep(1)
    return True

# === 7. íŒŒì¼ í™•ì¥ì ë§¤ì¹­ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ===
def get_file_extension(language):
    language = language.lower()
    if "c++" in language or "cpp" in language:
        return ".cpp"
    elif "c" in language and "c++" not in language:
        return ".c"
    elif "java" in language:
        return ".java"
    elif "python" in language or "py" in language:
        return ".py"
    elif "javascript" in language or "js" in language:
        return ".js"
    else:
        return ".txt"

# === 8. í˜ì´ì§€ ë‚´ë¹„ê²Œì´ì…˜ ì²˜ë¦¬ í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ===
def get_next_page_top(soup):
    next_page_link = soup.find('a', string='Next Page')
    if next_page_link:
        next_url = next_page_link.get('href')
        top = next_url.split('top=')[1].split('&')[0]
        prevtop = next_url.split('prevtop=')[1] if 'prevtop' in next_url else None
        return top, prevtop
    return None, None

# === 9. ë©”ì¸ í•¨ìˆ˜ ìˆ˜ì • ===
def main():
    if not os.path.exists(save_root):
        os.makedirs(save_root)
    
    # ë¡œê·¸ì¸ ì²˜ë¦¬
    session = login(username, password)
    if not session:
        return
    
    print(f"âœ… AScode.orgì— ë¡œê·¸ì¸ëœ ìƒíƒœì…ë‹ˆë‹¤. ì‚¬ìš©ì: {username}")
    page = 1
    max_pages = 20
    top = None
    prevtop = None

    while page <= max_pages:
        print(f"====== í˜ì´ì§€ {page} ì²˜ë¦¬ ì‹œì‘ ======")
        if not save_code_from_page(session, username, top, prevtop):
            print(f"í˜ì´ì§€ {page}ì—ì„œ ì²˜ë¦¬ ì¤‘ë‹¨ - ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ")
            break

        page_html = fetch_user_submissions(session, username, top, prevtop)
        if page_html:
            soup = BeautifulSoup(page_html, 'html.parser')
            top, prevtop = get_next_page_top(soup)
            if top:
                page += 1
                continue
        break
    print("ğŸ‰ ëª¨ë“  ì½”ë“œ ë‹¤ìš´ë¡œë“œ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ë‹¤ìš´ë¡œë“œëœ ì½”ë“œëŠ” {save_root} í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
